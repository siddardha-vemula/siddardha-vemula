{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "file-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"Lab Session Data.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "analyze-purchase-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1: Matrix Segregation and Analysis\n",
    "def analyze_purchase_data():\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=\"Purchase data\")\n",
    "        purchase_matrix = df.iloc[:, 1:4].values\n",
    "        purchase_amounts = df.iloc[:, 4].values.reshape(-1, 1)\n",
    "        dimensionality = purchase_matrix.shape[1]\n",
    "        num_vectors = purchase_matrix.shape[0]\n",
    "        rank_A = np.linalg.matrix_rank(purchase_matrix)\n",
    "        purchase_matrix_pinv = np.linalg.pinv(purchase_matrix)\n",
    "        product_costs = np.dot(purchase_matrix_pinv, purchase_amounts).flatten()\n",
    "        print(\"A1 Results:\")\n",
    "        print(f\"Dimensionality: {dimensionality}\")\n",
    "        print(f\"Number of Vectors: {num_vectors}\")\n",
    "        print(f\"Rank of A: {rank_A}\")\n",
    "        print(f\"Product Costs: {product_costs}\")\n",
    "        return dimensionality, num_vectors, rank_A, product_costs\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None, None, None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "compute-model-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2: Compute Model Vector X\n",
    "def compute_model_vector():\n",
    "    _, _, _, product_costs = analyze_purchase_data()\n",
    "    if product_costs is not None:\n",
    "        print(\"A2 Result:\")\n",
    "        print(f\"Model Vector X (Product Costs): {product_costs}\")\n",
    "        return product_costs\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "classify-customers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3: Customer Classification\n",
    "def classify_customers():\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=\"Purchase data\")\n",
    "        df[\"Customer Class\"] = np.where(df.iloc[:, 4] > 200, \"RICH\", \"POOR\")\n",
    "        print(\"A3 Result:\")\n",
    "        print(df[[\"Customer Class\"]])\n",
    "        return df[[\"Customer Class\"]]\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read 'Purchase data' from Excel.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "analyze-irctc-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4: IRCTC Stock Analysis\n",
    "def analyze_irctc_stock():\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=\"IRCTC Stock Price\")\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "        df[\"Day\"] = df[\"Date\"].dt.day_name()\n",
    "        mean_price = statistics.mean(df[\"Price\"])\n",
    "        variance_price = statistics.variance(df[\"Price\"])\n",
    "        wednesday_mean = df[df[\"Day\"] == \"Wednesday\"][\"Price\"].mean()\n",
    "        april_mean = df[df[\"Date\"].dt.month == 4][\"Price\"].mean()\n",
    "        prob_loss = (df[\"Chg%\"] < 0).mean()\n",
    "        prob_profit_wed = df[(df[\"Day\"] == \"Wednesday\") & (df[\"Chg%\"] > 0)][\"Chg%\"].count() / df[df[\"Day\"] == \"Wednesday\"][\"Chg%\"].count()\n",
    "        print(\"A4 Results:\")\n",
    "        print(f\"Mean Price: {mean_price}\")\n",
    "        print(f\"Variance Price: {variance_price}\")\n",
    "        print(f\"Wednesday Mean Price: {wednesday_mean}\")\n",
    "        print(f\"April Mean Price: {april_mean}\")\n",
    "        print(f\"Probability of Loss: {prob_loss}\")\n",
    "        print(f\"Probability of Profit on Wednesday: {prob_profit_wed}\")\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.scatterplot(x=df[\"Day\"], y=df[\"Chg%\"])\n",
    "        plt.xlabel(\"Day of the Week\")\n",
    "        plt.ylabel(\"Change %\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Change % vs. Day of the Week\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return mean_price, variance_price, wednesday_mean, april_mean, prob_loss, prob_profit_wed\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None, None, None, None, None, None\n",
    "    except KeyError:\n",
    "        print(\"Error: One or more required columns ('Price', 'Chg%', 'Date') are missing from the Excel sheet.\")\n",
    "        return None, None, None, None, None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read 'IRCTC Stock Price' from Excel.\")\n",
    "        return None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "explore-thyroid-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5: Data Exploration\n",
    "def explore_thyroid_data():\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=\"thyroid0387_UCI\")\n",
    "        df.replace('?', np.nan, inplace=True)\n",
    "        df = df.infer_objects()\n",
    "        missing_values = df.isnull().sum()\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = LabelEncoder().fit_transform(df[col])\n",
    "        print(\"A5 Results:\")\n",
    "        print(df.describe())\n",
    "        print(\"Missing Values:\\n\", missing_values)\n",
    "        return df.describe(), missing_values\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None, None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "impute-missing-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6: Data Imputation\n",
    "def impute_missing_data():\n",
    "    try:\n",
    "        df = pd.read_excel(xls, sheet_name=\"thyroid0387_UCI\")\n",
    "        df.replace('?', np.nan, inplace=True)\n",
    "        df = df.infer_objects()\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in ['float64', 'int64']:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        print(\"A6 Results:\")\n",
    "        print(df)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not read specified sheet from Excel file.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "normalize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A7: Data Normalization\n",
    "def normalize_data():\n",
    "    df = impute_missing_data()\n",
    "    if df is None:\n",
    "        return None\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    print(\"A7 Results:\")\n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "calculate-jaccard-smc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A8: Jaccard and SMC Similarity\n",
    "def calculate_jaccard_smc():\n",
    "    df = normalize_data()\n",
    "    if df is None:\n",
    "        return None, None\n",
    "    vector1 = df.iloc[0, :].values\n",
    "    vector2 = df.iloc[1, :].values\n",
    "    f11 = np.sum((vector1 == 1) & (vector2 == 1))\n",
    "    f00 = np.sum((vector1 == 0) & (vector2 == 0))\n",
    "    f10 = np.sum((vector1 == 1) & (vector2 == 0))\n",
    "    f01 = np.sum((vector1 == 0) & (vector2 == 1))\n",
    "    denominator = (f01 + f10 + f11)\n",
    "    JC = f11 / denominator if denominator != 0 else 0\n",
    "    SMC = (f11 + f00) / (f00 + f01 + f10 + f11) if (f00 + f01 + f10 + f11) != 0 else 0\n",
    "    print(\"A8 Results:\")\n",
    "    print(f\"Jaccard Coefficient: {JC}, SMC: {SMC}\")\n",
    "    return JC, SMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "calculate-cosine-similarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A9: Cosine Similarity\n",
    "def calculate_cosine_similarity():\n",
    "    df = normalize_data()\n",
    "    if df is None:\n",
    "        return None\n",
    "    vector1 = df.iloc[0, :].values.reshape(1, -1)\n",
    "    vector2 = df.iloc[1, :].values.reshape(1, -1)\n",
    "    result = cosine_similarity(vector1, vector2)[0][0]\n",
    "    print(\"A9 Result:\", result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "plot-similarity-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A10: Heatmap Plot for Similarity Measures\n",
    "def plot_similarity_heatmap():\n",
    "    df = normalize_data()\n",
    "    if df is None:\n",
    "        return None\n",
    "    df_subset = df.iloc[:20, :]\n",
    "    similarity_matrix = np.zeros((20, 20))\n",
    "    for i in range(20):\n",
    "        for j in range(20):\n",
    "            if i != j:\n",
    "                similarity_matrix[i, j] = np.linalg.norm(df_subset.iloc[i] - df_subset.iloc[j])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(similarity_matrix, annot=False, cmap='coolwarm')\n",
    "    plt.title(\"Heatmap of Euclidean Distances (Dissimilarity)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"A10 Result: (Euclidean Distance Matrix - Not Printed for brevity)\")\n",
    "    return similarity_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
